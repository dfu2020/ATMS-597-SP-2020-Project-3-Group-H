## ATMS-597-SP-2020-Project-3-Group-H
README.md for Project 3 Group H

Group members: Dongwei Fu, Alex Adams, Xinchang Li

========================Project-3-Group-H.py README===============================

We are tasked to extract weather data from [Global Precipitaiton Climatology Project (GPCP)](https://www.ncei.noaa.gov/data/global-precipitation-climatology-project-gpcp-daily/access/) and National Centers for Environmental Prediction (NCEP) [reanalysis data from the NOAA Physical Sciences Division THREDDS server](https://www.esrl.noaa.gov/psd/thredds/catalog/Datasets/catalog.html), reduce and analyze those data on extreme precipitation days in Melbourne, Australia during summer months (DJF) for variables specified in the [instructions](https://github.com/swnesbitt/ATMS-597-SP-2020/blob/master/ATMS-597-SP-2020-Project-3/INSTRUCTIONS.md).

The code consists of three parts:
----------------------------------------------------------------------------------
       1. GPCP data downloading and statistics
       2. NCEP Reanalysis data downloading and computation
       3. Plotting NCEP Reanalysis data
----------------------------------------------------------------------------------
       
### Part 1       
In Part 1, GPCP data downloading is achieved through BeautifulSoup package,
a list of filenames is generated by parsing the html metadata, and each file
follows: download file -> load into xarray -> aggregate -> delete file
sequence to save memory and disk space. 

Once all files have been processed, we end up with the xarray dataset that has
all the days of global precipitation values from 1996.10 to 2019.11, and the 
xarray dataset is then written into netcdf file to store in a local drive. 

We select 'DJF' months by using ```xr.DataArray.sel(time=(mdata['time.season'] == 'DJF'))```
and use ```xr.DataArray.sel(longitude=,latitude=, method='nearest')``` to select
the gridpoint closest to Melbourne, Aus.
We then drop all values that are bad data or fill-values to compute the 95-
percentile precipitation value using ```np.percentile(,95)```.

The Cumulative Probability Distribution Function is plotted using matplotlib.
Finally, the days of precipitation exceeding the 95 percentile threhold is then
written into a new .nc file.

### Part 2
Long term mean (LTM) fields for the base period (1981 - 2010, monthly averaged) and the daily files for the extreme precipitation days (XPRECIP) determined in Part 1 are retrieved and reduced from the THREDDS server in two different ways: 
1) **Compact**: a dictionary is created with variable names, URLs and other information essential for data retrieval and reduction, and a `for` loop (or two nested `for` loops for looping through years) is used to loop through, retrieve and concatenate data for the selected variables. The data are stored in `xarray.DataArrays` which are consoladated into dictionaries; 
2) **Direct**: data for each variable is explicitly specified, retrieved and reduced with one line of code.

Anomalies for the expreme precipitation days are then calculated to be the difference between the XPRECIP mean and the LTM for each variable per grid. Note that some units are inconsistent between the two mean fields and are conformed before anomaly calculations.

### Part 3
XPRECIP means, LTMs and anomalies are plotted for the whole Globe using Cartopy and matplotlib. Contours, filled contours or vector plots are used based on the variables. Melbourne is marked by a red or black star in each plot for reference.

(Alex: maybe say something about the vector plot and why it's rotated for 180?)
      
### Known caveats
1) When retrieving data using the **Compact** method, the temporal loop might terminate if there's no XPRECIP days in one of the years. An `if` statement could be added to check each timestep and skip that year if no dates are found.
2) (maybe put that plot thing here?)


